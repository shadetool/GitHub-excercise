{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shadetool/GitHub-excercise/blob/main/Fase_III_Experimento_2_P1_Random_Forest_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-tM5z7wnIjEc"
      },
      "cell_type": "markdown",
      "source": [
        "![image](https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/notebooks/headers/AutoAI-Banner_Pipeline-Notebook.png)\n",
        "# Pipeline Notebook - AutoAI Notebook v1.18.4\n",
        "\n",
        "Consider these tips for working with an auto-generated notebook:\n",
        "- Notebook code generated using AutoAI will execute successfully. If you modify the notebook, we cannot guarantee it will run successfully.\n",
        "- This pipeline is optimized for the original data set. The pipeline might fail or produce sub-optimal results if used with different data.  If you want to use a different data set, consider retraining the AutoAI experiment to generate a new pipeline. For more information, see <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Cloud Platform</a>.\n",
        "- Before modifying the pipeline or trying to re-fit the pipeline, consider that the code converts dataframes to numpy arrays before fitting the pipeline (a current restriction of the preprocessor pipeline).\n"
      ]
    },
    {
      "metadata": {
        "id": "4t9gbknqIjEf"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"content\"></a>\n",
        "## Notebook content\n",
        "\n",
        "This notebook contains a Scikit-learn representation of AutoAI pipeline. This notebook introduces commands for retrieving data, training the model, and testing the model.\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.10 and scikit-learn 1.1.1."
      ]
    },
    {
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "rytQbXt9IjEg"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook goals\n",
        "\n",
        "-  Scikit-learn pipeline definition\n",
        "-  Pipeline training\n",
        "-  Pipeline evaluation\n",
        "\n",
        "## Contents\n",
        "\n",
        "This notebook contains the following parts:\n",
        "\n",
        "**[Setup](#setup)**<br>\n",
        "&nbsp;&nbsp;[Package installation](#install)<br>\n",
        "&nbsp;&nbsp;[AutoAI experiment metadata](#variables_definition)<br>\n",
        "&nbsp;&nbsp;[Watson Machine Learning connection](#connection)<br>\n",
        "**[Pipeline inspection](#inspection)** <br>\n",
        "&nbsp;&nbsp;[Read training data with train and test data split](#read)<br>\n",
        "&nbsp;&nbsp;[Create pipeline](#preview_model_to_python_code)<br>\n",
        "&nbsp;&nbsp;[Train pipeline model](#train)<br>\n",
        "&nbsp;&nbsp;[Test pipeline model](#test_model)<br>\n",
        "&nbsp;&nbsp;[Forecast](#fore)<br>\n",
        "**[Store the model](#saving)**<br>\n",
        "**[Summary and next steps](#summary_and_next_steps)**<br>\n",
        "**[Copyrights](#copyrights)**"
      ]
    },
    {
      "metadata": {
        "id": "KP5t6AKwIjEg"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"setup\"></a>\n",
        "# Setup"
      ]
    },
    {
      "metadata": {
        "id": "1jVG8nwCIjEg"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"install\"></a>\n",
        "## Package installation\n",
        "Before you use the sample code in this notebook, install the following packages:\n",
        " - ibm_watson_machine_learning,\n",
        " - autoai-ts-libs,\n",
        " - scikit-learn\n"
      ]
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-12T14:00:45.009458Z",
          "iopub.status.busy": "2020-10-12T14:00:45.007968Z",
          "iopub.status.idle": "2020-10-12T14:00:46.037702Z",
          "shell.execute_reply": "2020-10-12T14:00:46.038270Z"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "L23mFLhzIjEg",
        "outputId": "f673e507-fc8e-4db1-ebfa-dc1524469b6c"
      },
      "cell_type": "code",
      "source": [
        "!pip install ibm-watson-machine-learning | tail -n 1\n",
        "!pip install -U 'autoai-ts-libs>=1.2.0,<4.0' | tail -n 1\n",
        "!pip install -U scikit-learn==1.1.1 | tail -n 1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed ibm-cos-sdk-2.13.3 ibm-cos-sdk-core-2.13.3 ibm-cos-sdk-s3transfer-2.13.3 ibm-watson-machine-learning-1.0.335 jmespath-1.0.1 lomond-0.3.3 urllib3-1.26.18\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.15.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.1 which is incompatible.\n",
            "plotnine 0.12.4 requires statsmodels>=0.14.0, but you have statsmodels 0.13.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alchemy-config-1.1.2 alchemy-logging-1.2.1 anytree-2.12.1 autoai-ts-libs-3.0.17 black-23.11.0 boto3-1.33.9 botocore-1.33.9 click-8.0.4 deprecated-1.2.14 dill-0.3.7 gast-0.4.0 greenery-3.3.3 hyperopt-0.2.5 ijson-3.2.3 import-tracker-3.1.5 jpype1-1.4.1 jsonref-1.1.0 jsons-1.3.1 jsonschema-specifications-2023.7.1 jsonsubschema-0.0.7 keras-2.12.0 lale-0.7.9 munch-4.0.0 mypy-extensions-1.0.0 pathspec-0.11.2 portion-2.4.2 referencing-0.30.0 s3transfer-0.8.2 scikit-learn-1.1.1 scipy-1.10.1 semver-3.0.2 setuptools-65.6.3 simplejson-3.17.6 statsmodels-0.13.5 tensorboard-2.12.3 tensorflow-2.12.1 tensorflow-estimator-2.12.0 typish-1.9.3 xgboost-1.6.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.1) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xQhbLrkXIjEi"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"variables_definition\"></a>\n",
        "## AutoAI experiment metadata\n",
        "The following cell contains the training data connection details.  \n",
        "**Note**: The connection might contain authorization credentials, so be careful when sharing the notebook."
      ]
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-12T14:00:49.797633Z",
          "iopub.status.busy": "2020-10-12T14:00:49.796778Z",
          "iopub.status.idle": "2020-10-12T14:00:57.182715Z",
          "shell.execute_reply": "2020-10-12T14:00:57.183132Z"
        },
        "pycharm": {
          "is_executing": true
        },
        "id": "pmUlq10CIjEi"
      },
      "cell_type": "code",
      "source": [
        "from ibm_watson_machine_learning.helpers import DataConnection\n",
        "from ibm_watson_machine_learning.helpers import ContainerLocation\n",
        "\n",
        "training_data_references = [\n",
        "    DataConnection(\n",
        "        data_asset_id='6a7d2546-04c5-404c-8753-19b6ba790e7e'\n",
        "    ),\n",
        "]\n",
        "training_result_reference = DataConnection(\n",
        "    location=ContainerLocation(\n",
        "        path='auto_ml/431d95fb-88d0-4faf-bd87-b49e7e863f52/wml_data/24dc8c13-0a3d-4f75-b198-02abc902462f/data/autoai-ts',\n",
        "        model_location='auto_ml/431d95fb-88d0-4faf-bd87-b49e7e863f52/wml_data/24dc8c13-0a3d-4f75-b198-02abc902462f/data/autoai-ts/model.zip',\n",
        "        training_status='auto_ml/431d95fb-88d0-4faf-bd87-b49e7e863f52/wml_data/24dc8c13-0a3d-4f75-b198-02abc902462f/training-status.json'\n",
        "    )\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Lfr77qxIjEi"
      },
      "cell_type": "markdown",
      "source": [
        "The following cell contains input parameters provided to run the AutoAI experiment in Watson Studio."
      ]
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-12T14:00:57.187305Z",
          "iopub.status.busy": "2020-10-12T14:00:57.186602Z",
          "iopub.status.idle": "2020-10-12T14:00:57.188392Z",
          "shell.execute_reply": "2020-10-12T14:00:57.188878Z"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8qq0X4iQIjEi"
      },
      "cell_type": "code",
      "source": [
        "experiment_metadata = dict(\n",
        "    prediction_type='timeseries',\n",
        "    prediction_columns=['TOTAL_ACCIDENTES', 'SUMA_HERIDOS'],\n",
        "    csv_separator=',',\n",
        "    holdout_size=20,\n",
        "    training_data_references=training_data_references,\n",
        "    training_result_reference=training_result_reference,\n",
        "    timestamp_column_name=-1,\n",
        "    backtest_num=4,\n",
        "    pipeline_type='all',\n",
        "    customized_pipelines=[],\n",
        "    lookback_window=15,\n",
        "    forecast_window=1,\n",
        "    max_num_daub_ensembles=3,\n",
        "    feature_columns=['TOTAL_ACCIDENTES', 'SUMA_HERIDOS', 'ANIO', 'NUMERO_MES', 'ID_ESTADO', 'ID_MUNICIPIO', 'SUMA_MUERTOS'],\n",
        "    future_exogenous_available=True,\n",
        "    gap_len=0,\n",
        "    deployment_url='https://eu-de.ml.cloud.ibm.com',\n",
        "    project_id='fc5ee1ab-982f-4266-b959-64501c8f4638',\n",
        "    numerical_imputation_strategy=['FlattenIterative', 'Linear', 'Cubic', 'Previous']\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPiCdMSfIjEj"
      },
      "cell_type": "markdown",
      "source": [
        "## Set `n_jobs` parameter to the number of available CPUs"
      ]
    },
    {
      "metadata": {
        "id": "k7GJBJh_IjEj"
      },
      "cell_type": "code",
      "source": [
        "import os, ast\n",
        "CPU_NUMBER = -1\n",
        "if 'RUNTIME_HARDWARE_SPEC' in os.environ:\n",
        "    CPU_NUMBER = int(ast.literal_eval(os.environ['RUNTIME_HARDWARE_SPEC'])['num_cpu'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i9CEHVTpIjEj"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"connection\"></a>\n",
        "## Watson Machine Learning connection\n",
        "\n",
        "This cell defines the credentials required to work with the Watson Machine Learning service.\n",
        "\n",
        "**Action**: Provide the IBM Cloud apikey, For details, see [documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey)."
      ]
    },
    {
      "metadata": {
        "id": "5wLxkDLuIjEj"
      },
      "cell_type": "code",
      "source": [
        "api_key = 'gBcOZ48ucH8FolbmXVlnl9Vv28lagQW8DEzuOxT8bIzP'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bruy8_DBIjEk"
      },
      "cell_type": "code",
      "source": [
        "wml_credentials = {\n",
        "    \"apikey\": api_key,\n",
        "    \"url\": experiment_metadata['deployment_url']\n",
        "    }\n",
        "\n",
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "039z-112IjEk"
      },
      "cell_type": "code",
      "source": [
        "from ibm_watson_machine_learning import APIClient\n",
        "\n",
        "wml_client = APIClient(wml_credentials)\n",
        "\n",
        "if 'space_id' in experiment_metadata:\n",
        "    wml_client.set.default_space(experiment_metadata['space_id'])\n",
        "else:\n",
        "    wml_client.set.default_project(experiment_metadata['project_id'])\n",
        "\n",
        "training_data_references[0].set_client(wml_client)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYH-oSx8IjEk"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"inspection\"></a>\n",
        "# Pipeline inspection"
      ]
    },
    {
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "aQlFAfDPIjEk"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"read\"></a>\n",
        "## Read training data with train and test data split\n",
        "\n",
        "Retrieve training dataset from AutoAI experiment as pandas DataFrame.\n",
        "\n",
        "**Note**: If reading data results in an error, provide data as Pandas DataFrame object, for example, reading .CSV file with `pandas.read_csv()`"
      ]
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-12T14:01:16.076169Z",
          "iopub.status.busy": "2020-10-12T14:01:16.075589Z",
          "iopub.status.idle": "2020-10-12T14:01:19.190233Z",
          "shell.execute_reply": "2020-10-12T14:01:19.190807Z"
        },
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "E0x7o9CHIjEk"
      },
      "cell_type": "code",
      "source": [
        "train_X, test_X, train_y, test_y = training_data_references[0].read(experiment_metadata=experiment_metadata, with_holdout_split=True, use_flight=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "cayvfwxrIjEk"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"preview_model_to_python_code\"></a>\n",
        "## Create pipeline\n",
        "In the next cell, you can find the Scikit-learn definition of the selected AutoAI pipeline."
      ]
    },
    {
      "metadata": {
        "id": "UmEptZKhIjEl"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import statements."
      ]
    },
    {
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "OtuKTBjNIjEl"
      },
      "cell_type": "code",
      "source": [
        "from autoai_ts_libs.utils.ts_pipeline import TSPipeline\n",
        "from autoai_ts_libs.transforms.imputers import flatten_iterative\n",
        "import autoai_ts_libs.srom.imputers.interpolators\n",
        "import autoai_ts_libs.srom.imputers.extended_iterative_imputer\n",
        "from autoai_ts_libs.sklearn.autoai_ts_pipeline import AutoaiTSPipeline\n",
        "from autoai_ts_libs.sklearn.mvp_windowed_transformed_target_estimators import (\n",
        "    AutoaiWindowTransformedTargetRegressor,\n",
        ")\n",
        "from autoai_ts_libs.sklearn.small_data_window_transformers import (\n",
        "    SmallDataWindowTransformer,\n",
        ")\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYeGkG2QIjEl"
      },
      "cell_type": "markdown",
      "source": [
        "#### Pipeline definition."
      ]
    },
    {
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "8oMW0o6iIjEl"
      },
      "cell_type": "code",
      "source": [
        "flatten_iterative = flatten_iterative(\n",
        "    base_imputer=autoai_ts_libs.srom.imputers.interpolators.PreMLImputer(\n",
        "        missing_values=float(\"nan\")\n",
        "    ),\n",
        "    missing_val_identifier=float(\"nan\"),\n",
        "    model_imputer=autoai_ts_libs.srom.imputers.extended_iterative_imputer.ExtendedIterativeImputer(\n",
        "        missing_values=float(\"nan\"), random_state=1\n",
        "    ),\n",
        ")\n",
        "small_data_window_transformer = SmallDataWindowTransformer(lookback_window=15)\n",
        "simple_imputer = SimpleImputer(missing_values=float(\"nan\"))\n",
        "random_forest_regressor = RandomForestRegressor(\n",
        "    n_estimators=500, max_depth=30, n_jobs=CPU_NUMBER, random_state=33\n",
        ")\n",
        "autoai_ts_pipeline_0 = AutoaiTSPipeline(\n",
        "    steps=[\n",
        "        (\"WTX\", small_data_window_transformer),\n",
        "        (\"imputer\", simple_imputer),\n",
        "        (\"est\", random_forest_regressor),\n",
        "    ]\n",
        ")\n",
        "autoai_window_transformed_target_regressor = (\n",
        "    AutoaiWindowTransformedTargetRegressor(\n",
        "        feature_columns=[0, 1],\n",
        "        lookback_window=15,\n",
        "        random_state=33,\n",
        "        regressor=autoai_ts_pipeline_0,\n",
        "        short_name=\"WindowRandomForest\",\n",
        "        target_columns=[0, 1],\n",
        "    )\n",
        ")\n",
        "autoai_ts_pipeline = AutoaiTSPipeline(\n",
        "    steps=[(\"windowedttr\", autoai_window_transformed_target_regressor)]\n",
        ")\n",
        "pipeline = TSPipeline(\n",
        "    steps=[\n",
        "        (\"flatten_iterative_imputer\", flatten_iterative),\n",
        "        (\n",
        "            \"<class 'autoai_ts_libs.sklearn.autoai_ts_pipeline.AutoaiTSPipeline'>\",\n",
        "            autoai_ts_pipeline,\n",
        "        ),\n",
        "    ],\n",
        "    feature_columns=[0, 1],\n",
        "    target_columns=[0, 1],\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xqkYORodIjEl"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"train\"></a>\n",
        "## Train pipeline model\n"
      ]
    },
    {
      "metadata": {
        "id": "az08l23oIjEl"
      },
      "cell_type": "markdown",
      "source": [
        "### Define scorer from the optimization metric\n",
        "This cell constructs the cell scorer based on the experiment metadata."
      ]
    },
    {
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "KFTTyGmeIjEm"
      },
      "cell_type": "code",
      "source": [
        "from autoai_ts_libs.utils.metrics import get_scorer\n",
        "\n",
        "scorer = get_scorer(\"neg_avg_symmetric_mean_absolute_percentage_error\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Gwet32u-IjEm"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"test_model\"></a>\n",
        "### Fit pipeline model\n",
        "In this cell, the pipeline is fitted."
      ]
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-12T14:01:19.291734Z",
          "iopub.status.busy": "2020-10-12T14:01:19.244735Z",
          "iopub.status.idle": "2020-10-12T14:01:19.338461Z",
          "shell.execute_reply": "2020-10-12T14:01:19.338958Z"
        },
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "scrolled": true,
        "id": "jLl3Y9ccIjEm"
      },
      "cell_type": "code",
      "source": [
        "pipeline.fit(train_X.values, train_y.values);"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IuUMbfZUIjEm"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"test_model\"></a>\n",
        "## Test pipeline model"
      ]
    },
    {
      "metadata": {
        "id": "3ZKicAHWIjEm"
      },
      "cell_type": "markdown",
      "source": [
        "Score the fitted pipeline with the generated scorer using the holdout dataset."
      ]
    },
    {
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-12T14:02:03.910267Z",
          "iopub.status.busy": "2020-10-12T14:02:03.909710Z",
          "iopub.status.idle": "2020-10-12T14:02:03.914154Z",
          "shell.execute_reply": "2020-10-12T14:02:03.914727Z"
        },
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEDtqOTVIjEm",
        "outputId": "7e1f6fc0-6c35-4c82-ca01-cced05e55819"
      },
      "cell_type": "code",
      "source": [
        "score = scorer(pipeline, test_X.values, test_y.values)\n",
        "print(score)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-77.66077956936752\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8R3IFa1IjEn",
        "outputId": "6989be2c-43b8-49fd-bb85-7dacc0bb2ec4"
      },
      "cell_type": "code",
      "source": [
        "pipeline.predict(test_X.values)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13.98867765, 10.44893512]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "y34PE8e0IjEn"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"forecast\"></a>\n",
        "## Forecast\n",
        "\n",
        "Forecast the future values of targets."
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIC2bcJNIjEn",
        "outputId": "96ed6987-ef55-45ac-bfe9-8e07e4240ec4"
      },
      "cell_type": "code",
      "source": [
        "pipeline.predict()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[28.62694954, 11.6830793 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "hd9sBuoFIjEo"
      },
      "cell_type": "markdown",
      "source": [
        "### Forecasting with the new observations\n",
        "Provide new observations values\n",
        "For example:\n",
        " - `a,b` are both targets and features, taken from `experiment_metadata[\"prediction_columns\"]`\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "a_newObs = [12, 22, 35, 46]\n",
        "b_newObs = [34, 23, 45, 34]\n",
        "newObs = np.mat([a_newObs, b_newObs]).T\n",
        "pipeline.predict(newObs)\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "9SKh1SZNIjEo"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"saving\"></a>\n",
        "## Store the model\n",
        "\n",
        "In this section you will learn how to store the retrained model."
      ]
    },
    {
      "metadata": {
        "id": "EIfSBy8lIjEo"
      },
      "cell_type": "code",
      "source": [
        "model_metadata = {\n",
        "    wml_client.repository.ModelMetaNames.NAME: 'P1 - Pretrained AutoAI pipeline'\n",
        "}\n",
        "\n",
        "stored_model_details = wml_client.repository.store_model(model=pipeline, meta_props=model_metadata, experiment_metadata=experiment_metadata)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2z51nnj3IjEo"
      },
      "cell_type": "markdown",
      "source": [
        "Inspect the stored model details."
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESGXnZG9IjEt",
        "outputId": "6d95253b-814d-47b8-c38c-37f05bde0631"
      },
      "cell_type": "code",
      "source": [
        "stored_model_details"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'entity': {'hybrid_pipeline_software_specs': [{'id': '01ce9391-1a79-5a33-94fb-2e134337f314',\n",
              "    'name': 'autoai-ts_rt23.1-py3.10'}],\n",
              "  'pipeline': {'id': '4dc7e9c1-afcc-4756-80e8-7ee0bede1b8b'},\n",
              "  'schemas': {'input': [{'fields': [{'metadata': {'modeling_role': 'both'},\n",
              "       'name': 'TOTAL_ACCIDENTES',\n",
              "       'type': 'integer'},\n",
              "      {'metadata': {'modeling_role': 'both'},\n",
              "       'name': 'SUMA_HERIDOS',\n",
              "       'type': 'integer'}],\n",
              "     'id': 'auto_ai_ts_input_schema'}],\n",
              "   'output': []},\n",
              "  'software_spec': {'id': '8c1a58c6-62b5-4dc4-987a-df751c2756b6',\n",
              "   'name': 'hybrid_0.1'},\n",
              "  'training_data_references': [{'connection': {},\n",
              "    'location': {'bucket': 'faseiiiaccidentesautomovilistcos-donotdelete-pr-kzrjhqax6wxmy1',\n",
              "     'href': '/v2/assets/6a7d2546-04c5-404c-8753-19b6ba790e7e?project_id=fc5ee1ab-982f-4266-b959-64501c8f4638',\n",
              "     'id': '6a7d2546-04c5-404c-8753-19b6ba790e7e',\n",
              "     'path': 'SSPV_07_2020_Estadistica2016_2020.csv'},\n",
              "    'schema': {'fields': [{'metadata': {'modeling_role': 'both'},\n",
              "       'name': 'TOTAL_ACCIDENTES',\n",
              "       'type': 'integer'},\n",
              "      {'metadata': {'modeling_role': 'both'},\n",
              "       'name': 'SUMA_HERIDOS',\n",
              "       'type': 'integer'}],\n",
              "     'id': 'auto_ai_ts_input_schema'},\n",
              "    'type': 'data_asset'}],\n",
              "  'type': 'wml-hybrid_0.1'},\n",
              " 'metadata': {'created_at': '2023-12-07T07:20:04.252Z',\n",
              "  'id': '5e5c1464-b74b-4bca-a73b-c8ff0b99aa4e',\n",
              "  'modified_at': '2023-12-07T07:20:13.847Z',\n",
              "  'name': 'P1 - Pretrained AutoAI pipeline',\n",
              "  'owner': 'IBMid-69300052S4',\n",
              "  'project_id': 'fc5ee1ab-982f-4266-b959-64501c8f4638',\n",
              "  'resource_key': '6702e7e5-c439-4775-8cbf-716ab3604565'},\n",
              " 'system': {'warnings': []}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "9IDf-5AEIjEt"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uW9LihVkIjEt"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"summary_and_next_steps\"></a>\n",
        "# Summary and next steps\n",
        "You successfully completed this notebook!\n",
        "You learned how to use AutoAI pipeline definition to train the model.\n",
        "Check out our [Online Documentation](https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_latest/cpd/overview/relnotes-4.0.html) for more samples, tutorials, documentation, how-tos, and blog posts."
      ]
    },
    {
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6LS01DjBIjEt"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"copyrights\"></a>\n",
        "### Copyrights\n",
        "\n",
        "Licensed Materials - Copyright © 2023 IBM. This notebook and its source code are released under the terms of the ILAN License. Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
        "\n",
        "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
        "\n",
        "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\">License Terms</a>\n",
        "\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.10",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}